{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffhandy/ColabScripts/blob/main/Convert_YOLO_to_CoreML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN0thoaDX7i0"
      },
      "source": [
        "## Instal Core ML Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XolwyUX1h0CZ"
      },
      "source": [
        "!pip install --upgrade coremltools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "Ct_6_k-MERwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"mshamrai/yolov8x-visdrone\"\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/{MODEL_ID}"
      ],
      "metadata": {
        "id": "rov0flWVpqry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model=YOLO('yolov8x-visdrone/best.pt')\n",
        "\n",
        "model.export(format='coreml',nms=True)"
      ],
      "metadata": {
        "id": "kIuU-PHFyU3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "84d681eb-dd44-49bc-93a7-96b8ca166b04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.42 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.00GHz)\n",
            "Model summary (fused): 268 layers, 68133198 parameters, 0 gradients, 257.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8x-visdrone/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (130.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
            "WARNING:coremltools:XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n",
            "WARNING:coremltools:TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
            "WARNING:coremltools:Torch version 2.2.1+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.1.0 is the most recent version that has been tested.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 7.1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n",
            "Converting PyTorch Frontend ==> MIL Ops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 776/778 [00:00<00:00, 3096.15 ops/s]\n",
            "Running MIL frontend_pytorch pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 131.66 passes/s]\n",
            "Running MIL default pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 10.28 passes/s]\n",
            "Running MIL backend_mlprogram pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 196.72 passes/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 7.1...\n",
            "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m pipeline success\n",
            "\u001b[34m\u001b[1mCoreML:\u001b[0m export success âœ… 64.3s, saved as 'yolov8x-visdrone/best.mlpackage' (130.2 MB)\n",
            "\n",
            "Export complete (74.2s)\n",
            "Results saved to \u001b[1m/content/yolov8x-visdrone\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8x-visdrone/best.mlpackage imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov8x-visdrone/best.mlpackage imgsz=640 data=/usr/local/lib/python3.9/dist-packages/ultralytics/datasets/VisDrone.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yolov8x-visdrone/best.mlpackage'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}